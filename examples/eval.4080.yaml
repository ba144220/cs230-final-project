# Model arguments
model_name: meta-llama/Llama-3.2-1B-Instruct
adapter_path: ./outputs/run_20241113_115341
load_in_4bit: true
load_in_8bit: false

line_length: 64
# channel_period: 32
# x_channel_offset: 0
# y_channel_offset: 1

# Dataset arguments
dataset_root_dir: ./datasets
dataset_names: ["self_generated", "wtq"]
table_extension: csv
train_max_samples_for_each_dataset: 80
val_max_samples_for_each_dataset: 240
test_max_samples_for_each_dataset: 240
shuffle_seed: 42

max_table_row_num: 32
max_table_width: 64

# Training arguments
batch_size: 4
max_seq_length: 2048
