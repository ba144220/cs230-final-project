{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collator\n",
    "from collators.data_collator_for_cell_tokenization import DataCollatorForCellTokenizer\n",
    "\n",
    "# Load dataset arguments\n",
    "collator = DataCollatorForCellTokenizer(\n",
    "    tokenizer=tokenizer, \n",
    "    max_seq_length=1024, \n",
    "    is_train=True, \n",
    "    table_cell_separator=\"|\",\n",
    "    row_offset=1,\n",
    "    column_offset=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset arguments\n",
    "from parsers.argument_classes import DatasetArguments\n",
    "from utils.datasets_loader import load_datasets\n",
    "\n",
    "dataset_args = DatasetArguments(\n",
    "    dataset_root_dir=\"../datasets\",\n",
    "    dataset_names=[\"wtq\"],\n",
    "    table_extension=\"csv\",\n",
    "    train_max_samples_for_each_dataset=14149,\n",
    "    val_max_samples_for_each_dataset=100,\n",
    "    test_max_samples_for_each_dataset=100,\n",
    ")\n",
    "\n",
    "datasets = load_datasets(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who was the top ranked swimmer in the semifinals?',\n",
       " 'answer': 'Dyana Calub',\n",
       " 'context': 'csv/204-csv/544.csv',\n",
       " 'id': 'nt-9309',\n",
       " 'task': 'wtq',\n",
       " 'direction': 'none',\n",
       " 'size': -1,\n",
       " 'table_row_num': 17,\n",
       " 'table_width': 20,\n",
       " 'table': '\"Rank\",\"Name\",\"Nationality\",\"Time\",\"Notes\"\\n\"1\",\"Dyana Calub\",\"Australia\",\"1:01.77\",\"Q\"\\n\"2\",\"Natalie Coughlin\",\"United States\",\"1:01.99\",\"Q\"\\n\"3\",\"Noriko Inada\",\"Japan\",\"1:02.00\",\"Q\"\\n\"4\",\"Haley Cope\",\"United States\",\"1:02.09\",\"Q\"\\n\"5\",\"Diana MacManus\",\"United States\",\"1:02.10\",\"Q\"\\n\"6\",\"Courtney Shealy\",\"United States\",\"1:02.28\",\"Q\"\\n\"7\",\"Aya Terakawa\",\"Japan\",\"1:02.39\",\"Q\"\\n\"8\",\"Giaan Rooney\",\"Australia\",\"1:02.53\",\"Q\"\\n\"9\",\"Erin Gammel\",\"Canada\",\"1:02.63\",\"\"\\n\"10\",\"Hannah McLean\",\"New Zealand\",\"1:02.82\",\"\"\\n\"11\",\"Melissa Morgan\",\"Australia\",\"1:02.86\",\"\"\\n\"12\",\"Reiko Nakamura\",\"Japan\",\"1:02.91\",\"\"\\n\"13\",\"Michelle Lischinsky\",\"Canada\",\"1:03.22\",\"\"\\n\"14\",\"Jennifer Fratesi\",\"Canada\",\"1:03.42\",\"\"\\n\"15\",\"Kelly Stefanyshyn\",\"Canada\",\"1:03.44\",\"\"\\n\"16\",\"Clementine Stoney\",\"Australia\",\"1:03.52\",\"\"\\n'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(tokens):\n",
    "    line = \"\"\n",
    "    for i in tokens:\n",
    "        decoded_string = collator.tokenizer.decode(i)\n",
    "        # Append the current token and its decoded representation to the line\n",
    "        line += f\"{repr(decoded_string)} \"\n",
    "        # line += f\"{i} {repr(decoded_string)} \"\n",
    "        # Check if the decoded string contains a newline character\n",
    "        if '\\n' in decoded_string:\n",
    "            # Print the accumulated line and reset it\n",
    "            print(line.strip())\n",
    "            line = \"\"\n",
    "    # Print any remaining content in the line\n",
    "    if line:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test _tokenize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([128006,   9125, 128007,    271, 128009]), array([0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0]))\n",
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\n",
    "token_ids = collator._tokenize_string(\n",
    "    input_text,\n",
    "    include_eot=True,\n",
    "    include_header=True,\n",
    "    header_content=\"system\"\n",
    ")\n",
    "print(token_ids)\n",
    "print(collator.tokenizer.decode(token_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([128006,   9125, 128007,    271,   9906,     11,   1917,      0,\n",
      "         1115,    374,    264,   1633,   1317,    925,    430,   1288,\n",
      "          387,  44968,    311,    279,  24379,   5361,    315,    220,\n",
      "          843,     13,   1226,    690,   1101,   2997,    279,    842,\n",
      "          315,   1495,   4037,    520,    279,    842,     13, 128009]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Hello, world! This is a very long string that should be padded to the nearest multiple of 32. We will also include the end of text token at the end.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hello, world! This is a very long string that should be padded to the nearest multiple of 32. We will also include the end of text token at the end.\"\n",
    "token_ids = collator._tokenize_string(\n",
    "    input_text,\n",
    "    include_eot=True,\n",
    "    include_header=True,\n",
    "    header_content=\"system\"\n",
    ")\n",
    "print(token_ids)\n",
    "print(collator.tokenizer.decode(token_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test _cell_tokenize_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Rank\",\"Name\",\"Nationality\",\"Time\",\"Notes\"\n",
      "\"1\",\"Dyana Calub\",\"Australia\",\"1:01.77\",\"Q\"\n",
      "\"2\",\"Natalie Coughlin\",\"United States\",\"1:01.99\",\"Q\"\n",
      "\"3\",\"Noriko Inada\",\"Japan\",\"1:02.00\",\"Q\"\n",
      "\"4\",\"Haley Cope\",\"United States\",\"1:02.09\",\"Q\"\n",
      "\"5\",\"Diana MacManus\",\"United States\",\"1:02.10\",\"Q\"\n",
      "\"6\",\"Courtney Shealy\",\"United States\",\"1:02.28\",\"Q\"\n",
      "\"7\",\"Aya Terakawa\",\"Japan\",\"1:02.39\",\"Q\"\n",
      "\"8\",\"Giaan Rooney\",\"Australia\",\"1:02.53\",\"Q\"\n",
      "\"9\",\"Erin Gammel\",\"Canada\",\"1:02.63\",\"\"\n",
      "\"10\",\"Hannah McLean\",\"New Zealand\",\"1:02.82\",\"\"\n",
      "\"11\",\"Melissa Morgan\",\"Australia\",\"1:02.86\",\"\"\n",
      "\"12\",\"Reiko Nakamura\",\"Japan\",\"1:02.91\",\"\"\n",
      "\"13\",\"Michelle Lischinsky\",\"Canada\",\"1:03.22\",\"\"\n",
      "\"14\",\"Jennifer Fratesi\",\"Canada\",\"1:03.42\",\"\"\n",
      "\"15\",\"Kelly Stefanyshyn\",\"Canada\",\"1:03.44\",\"\"\n",
      "\"16\",\"Clementine Stoney\",\"Australia\",\"1:03.52\",\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = datasets[\"train\"][0][\"table\"]\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Rank' '|' 'Name' '|' 'National' 'ity' '|' 'Time' '|' 'Notes' '|\\n'\n",
      "'1' '|' 'D' 'y' 'ana' ' Cal' 'ub' '|' 'Australia' '|' '1' ':' '01' '.' '77' '|' 'Q' '|\\n'\n",
      "'2' '|' 'N' 'atal' 'ie' ' C' 'ough' 'lin' '|' 'United' ' States' '|' '1' ':' '01' '.' '99' '|' 'Q' '|\\n'\n",
      "'3' '|' 'Nor' 'iko' ' In' 'ada' '|' 'Japan' '|' '1' ':' '02' '.' '00' '|' 'Q' '|\\n'\n",
      "'4' '|' 'H' 'aley' ' C' 'ope' '|' 'United' ' States' '|' '1' ':' '02' '.' '09' '|' 'Q' '|\\n'\n",
      "'5' '|' 'D' 'iana' ' Mac' 'Man' 'us' '|' 'United' ' States' '|' '1' ':' '02' '.' '10' '|' 'Q' '|\\n'\n",
      "'6' '|' 'Court' 'ney' ' She' 'aly' '|' 'United' ' States' '|' '1' ':' '02' '.' '28' '|' 'Q' '|\\n'\n",
      "'7' '|' 'A' 'ya' ' Ter' 'ak' 'awa' '|' 'Japan' '|' '1' ':' '02' '.' '39' '|' 'Q' '|\\n'\n",
      "'8' '|' 'G' 'ia' 'an' ' Rooney' '|' 'Australia' '|' '1' ':' '02' '.' '53' '|' 'Q' '|\\n'\n",
      "'9' '|' 'Er' 'in' ' G' 'amm' 'el' '|' 'Canada' '|' '1' ':' '02' '.' '63' '|' 'nan' '|\\n'\n",
      "'10' '|' 'H' 'annah' ' Mc' 'Lean' '|' 'New' ' Zealand' '|' '1' ':' '02' '.' '82' '|' 'nan' '|\\n'\n",
      "'11' '|' 'Mel' 'issa' ' Morgan' '|' 'Australia' '|' '1' ':' '02' '.' '86' '|' 'nan' '|\\n'\n",
      "'12' '|' 'Re' 'iko' ' Nak' 'amura' '|' 'Japan' '|' '1' ':' '02' '.' '91' '|' 'nan' '|\\n'\n",
      "'13' '|' 'Michelle' ' L' 'isch' 'insky' '|' 'Canada' '|' '1' ':' '03' '.' '22' '|' 'nan' '|\\n'\n",
      "'14' '|' 'Jennifer' ' Fr' 'ates' 'i' '|' 'Canada' '|' '1' ':' '03' '.' '42' '|' 'nan' '|\\n'\n",
      "'15' '|' 'Kelly' ' Stef' 'any' 'sh' 'yn' '|' 'Canada' '|' '1' ':' '03' '.' '44' '|' 'nan' '|\\n'\n",
      "'16' '|' 'C' 'lement' 'ine' ' St' 'oney' '|' 'Australia' '|' '1' ':' '03' '.' '52' '|' 'nan' '|\\n'\n"
     ]
    }
   ],
   "source": [
    "table = collator._convert_csv_string_to_table(datasets[\"train\"][0][\"table\"])\n",
    "result = collator._cell_tokenize_table(table)\n",
    "pretty_print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2E Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 471])\n",
      "torch.Size([2, 471])\n",
      "torch.Size([2, 471])\n",
      "torch.Size([2, 471])\n",
      "torch.Size([2, 471])\n"
     ]
    }
   ],
   "source": [
    "result = collator([datasets[\"train\"][0], datasets[\"train\"][1]])\n",
    "print(result[\"input_ids\"].shape)\n",
    "print(result[\"row_ids\"].shape)\n",
    "print(result[\"column_ids\"].shape)\n",
    "print(result[\"attention_mask\"].shape)\n",
    "print(result[\"labels\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100, 16533,    25, 43048,  3444,  3400,\n",
      "           392,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100, 16533,    25,  3744,   220,   717,\n",
      "          -100]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input_ids tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  11190,\n",
      "          18328,    430,  11503,   4860,    922,    279,   2007,     13,   1472,\n",
      "           1193,   4320,    279,   3488,   1314,   1306,    364,  16533,     25,\n",
      "            364, 128009, 128006,    882, 128007,    271,  23366,     91,    678,\n",
      "             91,  31912,    488,     91,   1489,     91,  22405,   7511,     16,\n",
      "             91,     35,     88,   3444,   3400,    392,     91,  49137,     91,\n",
      "             16,     25,   1721,     13,   2813,     91,     48,   7511,     17,\n",
      "             91,     45,   4306,    648,    356,   1409,   3817,     91,  23175,\n",
      "           4273,     91,     16,     25,   1721,     13,   1484,     91,     48,\n",
      "           7511,     18,     91,  33763,  24551,    763,   2649,     91,  49852,\n",
      "             91,     16,     25,   2437,     13,    410,     91,     48,   7511,\n",
      "             19,     91,     39,  43027,    356,   2862,     91,  23175,   4273,\n",
      "             91,     16,     25,   2437,     13,   2545,     91,     48,   7511,\n",
      "             20,     91,     35,  12699,   7553,   1692,    355,     91,  23175,\n",
      "           4273,     91,     16,     25,   2437,     13,    605,     91,     48,\n",
      "           7511,     21,     91,  76874,   3520,   3005,   5893,     91,  23175,\n",
      "           4273,     91,     16,     25,   2437,     13,   1591,     91,     48,\n",
      "           7511,     22,     91,     32,   7911,  10335,    587,  14406,     91,\n",
      "          49852,     91,     16,     25,   2437,     13,   2137,     91,     48,\n",
      "           7511,     23,     91,     38,    689,    276,  80730,     91,  49137,\n",
      "             91,     16,     25,   2437,     13,   4331,     91,     48,   7511,\n",
      "             24,     91,  20027,    258,    480,   8836,    301,     91,  37031,\n",
      "             91,     16,     25,   2437,     13,   5495,     91,  19285,   7511,\n",
      "            605,     91,     39,  44104,   4584,  49862,     91,   3648,  17340,\n",
      "             91,     16,     25,   2437,     13,   6086,     91,  19285,   7511,\n",
      "            806,     91,  40249,  22144,  23809,     91,  49137,     91,     16,\n",
      "             25,   2437,     13,   4218,     91,  19285,   7511,    717,     91,\n",
      "            697,  24551,  44329,  84817,     91,  49852,     91,     16,     25,\n",
      "           2437,     13,   5925,     91,  19285,   7511,   1032,     91,  83862,\n",
      "            445,  16438,  52541,     91,  37031,     91,     16,     25,   2839,\n",
      "             13,   1313,     91,  19285,   7511,    975,     91,  72526,   2939,\n",
      "            988,     72,     91,  37031,     91,     16,     25,   2839,     13,\n",
      "           2983,     91,  19285,   7511,    868,     91,  70172,  69420,   3852,\n",
      "            939,   1910,     91,  37031,     91,     16,     25,   2839,     13,\n",
      "           2096,     91,  19285,   7511,    845,     91,     34,   1001,    483,\n",
      "            800,   2596,     91,  49137,     91,     16,     25,   2839,     13,\n",
      "           4103,     91,  19285,   7511,  14965,    574,    279,   1948,  21682,\n",
      "          16587,   1195,    304,    279,  66600,  24624,     30, 128009, 128006,\n",
      "          78191, 128007,    271,  16533,     25,  43048,   3444,   3400,    392,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
      "         128009, 128009, 128009],\n",
      "        [128000, 128006,   9125, 128007,    271,   2675,    527,    264,  11190,\n",
      "          18328,    430,  11503,   4860,    922,    279,   2007,     13,   1472,\n",
      "           1193,   4320,    279,   3488,   1314,   1306,    364,  16533,     25,\n",
      "            364, 128009, 128006,    882, 128007,    271,   5920,     91,   2903,\n",
      "             91,   5451,    586,   4984,   2457,    320,   5451,  14002,  18419,\n",
      "          33092,    586,   4984,   2457,    320,  79037,  18419,  33092,  28238,\n",
      "             91,   3936,     91,   5116,   7511,   5920,    220,     16,     91,\n",
      "          25141,     14,   5484,     34,    220,  11068,   1987,     12,     16,\n",
      "             91,   1049,     17,     91,   1049,     17,     91,   1049,     21,\n",
      "             91,  49165,     91,   1820,  43563,  12914,    315,  71089,     12,\n",
      "             22,     11,    279,  52547,    315,  71089,     12,     22,   2262,\n",
      "            482,   2722,     44,    320,   1199,    940,   3645,    369,  71089,\n",
      "             12,     22,      8,    323,    279,   8026,   3645,    369,  71089,\n",
      "             12,     22,  28887,    320,  37196,     44,      8,   7511,   5920,\n",
      "            220,     17,     91,  25141,     14,   5484,     34,    220,  11068,\n",
      "           1987,     12,     17,     91,   1049,     17,     91,   1049,     17,\n",
      "             91,  19285,     91,   5116,   7419,   4221,     91,  19285,   7511,\n",
      "           5920,    220,     18,     91,  25141,     14,   5484,     34,    220,\n",
      "          11068,   1987,     12,     18,     91,   1049,     17,     91,   1049,\n",
      "             17,     91,    679,     15,     91,   9789,     91,  19285,   7511,\n",
      "           5920,    220,     19,     91,  25141,     14,   5484,     34,    220,\n",
      "          11068,   1987,     12,     19,     91,   1049,     17,     91,   1049,\n",
      "             17,     91,   1049,     21,     91,  15097,     91,  19285,   7511,\n",
      "           5920,    220,     20,     91,  25141,     14,   5484,     34,    220,\n",
      "          11068,   1987,     12,     20,     91,   1049,     18,     91,   1049,\n",
      "             18,     91,   1049,     23,     91,  41504,  28034,   4096,  31956,\n",
      "             91,  19285,   7511,   5920,    220,     21,     91,  25141,     14,\n",
      "           5484,     34,    220,  11068,   1987,     12,     21,     91,   1049,\n",
      "             18,     91,   1049,     18,     91,    679,     15,    320,    679,\n",
      "             16,  18419,   9032,   3241,     91,  19285,   7511,   5920,    220,\n",
      "             22,     91,  25141,     14,   5484,     34,    220,  11068,   1987,\n",
      "             12,     22,     91,   1049,     18,     91,   1049,     18,     91,\n",
      "            679,     15,    320,    679,     16,  18419,   1128,  12057,   7649,\n",
      "             91,  19285,   7511,   5920,    220,     23,     91,  25141,     14,\n",
      "           5484,     34,   5091,    220,  11068,   1987,     12,     23,     91,\n",
      "           1049,     17,     91,   1049,     17,     91,    679,     15,     91,\n",
      "            849,  27523,    323,   1005,    315,  71089,     12,     22,  28887,\n",
      "             91,  19285,   7511,   5920,    220,     24,     91,  25141,     14,\n",
      "           5484,     34,    220,  11068,   1987,     12,     24,     91,   1049,\n",
      "             20,     91,   1049,     20,     91,      7,    679,     16,  18419,\n",
      "          63819,    323,   5990,     91,  19285,   7511,   5920,    220,    605,\n",
      "             91,  25141,     14,   5484,     34,    220,  11068,   1987,     12,\n",
      "            605,     91,   1049,     20,     91,   1049,     20,     91,  19285,\n",
      "             91,   8802,   7419,     91,  19285,   7511,   5920,    220,    806,\n",
      "             91,  25141,     14,   5484,     34,   5091,    220,  11068,   1987,\n",
      "             12,    806,     91,   1049,     20,     91,   1049,     20,     91,\n",
      "          19285,     91,     44,  22836,     12,     22,   5643,  62900,     91,\n",
      "          19285,   7511,   5920,    220,    717,     91,  25141,     14,   5484,\n",
      "             34,    220,  11068,   1987,     12,    717,     91,   1049,     23,\n",
      "             91,   1049,     23,     91,      7,    679,     16,  18419,   2929,\n",
      "           3645,     91,  19285,   7511,   8370,    961,    574,   4756,   5652,\n",
      "             30, 128009, 128006,  78191, 128007,    271,  16533,     25,   3744,\n",
      "            220,    717, 128009]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "row_ids tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    4,    4,\n",
      "            4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "            4,    4,    4,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
      "            5,    5,    5,    5,    5,    5,    5,    5,    5,    6,    6,    6,\n",
      "            6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
      "            6,    6,    6,    6,    7,    7,    7,    7,    7,    7,    7,    7,\n",
      "            7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    9,   10,   10,   10,\n",
      "           10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
      "           10,   10,   10,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,   12,   12,   12,\n",
      "           12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
      "           12,   13,   13,   13,   13,   13,   13,   13,   13,   13,   13,   13,\n",
      "           13,   13,   13,   13,   13,   13,   14,   14,   14,   14,   14,   14,\n",
      "           14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   15,\n",
      "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
      "           15,   15,   15,   15,   16,   16,   16,   16,   16,   16,   16,   16,\n",
      "           16,   16,   16,   16,   16,   16,   16,   16,   16,   16,   17,   17,\n",
      "           17,   17,   17,   17,   17,   17,   17,   17,   17,   17,   17,   17,\n",
      "           17,   17,   17,   17,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    3,    3,    3,    3,    3,    3,    3,\n",
      "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "            3,    3,    3,    3,    3,    3,    3,    3,    3,    4,    4,    4,\n",
      "            4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "            4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "            5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
      "            5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
      "            5,    5,    5,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
      "            6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
      "            6,    6,    6,    6,    6,    6,    6,    6,    6,    7,    7,    7,\n",
      "            7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,\n",
      "            7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,\n",
      "            7,    7,    7,    7,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "           10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
      "           10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
      "           10,   10,   10,   10,   10,   10,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,   12,   12,   12,\n",
      "           12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
      "           12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
      "           12,   12,   12,   12,   12,   13,   13,   13,   13,   13,   13,   13,\n",
      "           13,   13,   13,   13,   13,   13,   13,   13,   13,   13,   13,   13,\n",
      "           13,   13,   13,   13,   13,   13,   13,   13,   13,   13,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "column_ids tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    1,    2,\n",
      "            2,    3,    3,    3,    4,    4,    5,    5,    1,    1,    2,    2,\n",
      "            2,    2,    2,    2,    3,    3,    4,    4,    4,    4,    4,    4,\n",
      "            5,    5,    1,    1,    2,    2,    2,    2,    2,    2,    2,    3,\n",
      "            3,    3,    4,    4,    4,    4,    4,    4,    5,    5,    1,    1,\n",
      "            2,    2,    2,    2,    2,    3,    3,    4,    4,    4,    4,    4,\n",
      "            4,    5,    5,    1,    1,    2,    2,    2,    2,    2,    3,    3,\n",
      "            3,    4,    4,    4,    4,    4,    4,    5,    5,    1,    1,    2,\n",
      "            2,    2,    2,    2,    2,    3,    3,    3,    4,    4,    4,    4,\n",
      "            4,    4,    5,    5,    1,    1,    2,    2,    2,    2,    2,    3,\n",
      "            3,    3,    4,    4,    4,    4,    4,    4,    5,    5,    1,    1,\n",
      "            2,    2,    2,    2,    2,    2,    3,    3,    4,    4,    4,    4,\n",
      "            4,    4,    5,    5,    1,    1,    2,    2,    2,    2,    2,    3,\n",
      "            3,    4,    4,    4,    4,    4,    4,    5,    5,    1,    1,    2,\n",
      "            2,    2,    2,    2,    2,    3,    3,    4,    4,    4,    4,    4,\n",
      "            4,    5,    5,    1,    1,    2,    2,    2,    2,    2,    3,    3,\n",
      "            3,    4,    4,    4,    4,    4,    4,    5,    5,    1,    1,    2,\n",
      "            2,    2,    2,    3,    3,    4,    4,    4,    4,    4,    4,    5,\n",
      "            5,    1,    1,    2,    2,    2,    2,    2,    3,    3,    4,    4,\n",
      "            4,    4,    4,    4,    5,    5,    1,    1,    2,    2,    2,    2,\n",
      "            2,    3,    3,    4,    4,    4,    4,    4,    4,    5,    5,    1,\n",
      "            1,    2,    2,    2,    2,    2,    3,    3,    4,    4,    4,    4,\n",
      "            4,    4,    5,    5,    1,    1,    2,    2,    2,    2,    2,    2,\n",
      "            3,    3,    4,    4,    4,    4,    4,    4,    5,    5,    1,    1,\n",
      "            2,    2,    2,    2,    2,    2,    3,    3,    4,    4,    4,    4,\n",
      "            4,    4,    5,    5,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    1,    2,\n",
      "            2,    3,    3,    3,    3,    3,    3,    3,    3,    4,    4,    4,\n",
      "            4,    4,    4,    4,    5,    5,    5,    6,    6,    7,    7,    1,\n",
      "            1,    1,    1,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    3,    3,    3,    4,    4,    4,    5,    5,    5,    6,    6,\n",
      "            7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,\n",
      "            7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,\n",
      "            7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,\n",
      "            7,    7,    7,    7,    7,    1,    1,    1,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    3,    3,    3,    4,    4,\n",
      "            4,    5,    5,    6,    6,    6,    6,    7,    7,    1,    1,    1,\n",
      "            1,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    3,\n",
      "            3,    3,    4,    4,    4,    5,    5,    5,    6,    6,    7,    7,\n",
      "            1,    1,    1,    1,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    3,    3,    3,    4,    4,    4,    5,    5,    5,    6,\n",
      "            6,    7,    7,    1,    1,    1,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    3,    3,    3,    4,    4,    4,    5,\n",
      "            5,    5,    6,    6,    6,    6,    6,    7,    7,    1,    1,    1,\n",
      "            1,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    3,\n",
      "            3,    3,    4,    4,    4,    5,    5,    5,    5,    5,    5,    6,\n",
      "            6,    6,    7,    7,    1,    1,    1,    1,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    3,    3,    3,    4,    4,    4,\n",
      "            5,    5,    5,    5,    5,    5,    6,    6,    6,    6,    7,    7,\n",
      "            1,    1,    1,    1,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    3,    3,    3,    4,    4,    4,    5,    5,    5,\n",
      "            6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    7,    7,\n",
      "            1,    1,    1,    1,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    3,    3,    3,    4,    4,    4,    5,    5,    5,    5,\n",
      "            6,    6,    6,    6,    7,    7,    1,    1,    1,    1,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    3,    3,    3,    4,\n",
      "            4,    4,    5,    5,    6,    6,    6,    7,    7,    1,    1,    1,\n",
      "            1,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            3,    3,    3,    4,    4,    4,    5,    5,    6,    6,    6,    6,\n",
      "            6,    6,    6,    7,    7,    1,    1,    1,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    3,    3,    3,    4,    4,\n",
      "            4,    5,    5,    5,    5,    6,    6,    6,    7,    7,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(\"labels\", result[\"labels\"])\n",
    "print(\"-\"*100)\n",
    "print(\"attention_mask\", result[\"attention_mask\"])\n",
    "print(\"-\"*100)\n",
    "print(\"input_ids\", result[\"input_ids\"])\n",
    "print(\"-\"*100)\n",
    "print(\"row_ids\", result[\"row_ids\"])\n",
    "print(\"-\"*100)\n",
    "print(\"column_ids\", result[\"column_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank|Name|Nationality|Time|Notes|\n",
      "1|Dyana Calub|Australia|1:01.77|Q|\n",
      "2|Natalie Coughlin|United States|1:01.99|Q|\n",
      "3|Noriko Inada|Japan|1:02.00|Q|\n",
      "4|Haley Cope|United States|1:02.09|Q|\n",
      "5|Diana MacManus|United States|1:02.10|Q|\n",
      "6|Courtney Shealy|United States|1:02.28|Q|\n",
      "7|Aya Terakawa|Japan|1:02.39|Q|\n",
      "8|Giaan Rooney|Australia|1:02.53|Q|\n",
      "9|Erin Gammel|Canada|1:02.63|nan|\n",
      "10|Hannah McLean|New Zealand|1:02.82|nan|\n",
      "11|Melissa Morgan|Australia|1:02.86|nan|\n",
      "12|Reiko Nakamura|Japan|1:02.91|nan|\n",
      "13|Michelle Lischinsky|Canada|1:03.22|nan|\n",
      "14|Jennifer Fratesi|Canada|1:03.42|nan|\n",
      "15|Kelly Stefanyshyn|Canada|1:03.44|nan|\n",
      "16|Clementine Stoney|Australia|1:03.52|nan|\n",
      "\n",
      "\"Rank\",\"Name\",\"Nationality\",\"Time\",\"Notes\"\n",
      "\"1\",\"Dyana Calub\",\"Australia\",\"1:01.77\",\"Q\"\n",
      "\"2\",\"Natalie Coughlin\",\"United States\",\"1:01.99\",\"Q\"\n",
      "\"3\",\"Noriko Inada\",\"Japan\",\"1:02.00\",\"Q\"\n",
      "\"4\",\"Haley Cope\",\"United States\",\"1:02.09\",\"Q\"\n",
      "\"5\",\"Diana MacManus\",\"United States\",\"1:02.10\",\"Q\"\n",
      "\"6\",\"Courtney Shealy\",\"United States\",\"1:02.28\",\"Q\"\n",
      "\"7\",\"Aya Terakawa\",\"Japan\",\"1:02.39\",\"Q\"\n",
      "\"8\",\"Giaan Rooney\",\"Australia\",\"1:02.53\",\"Q\"\n",
      "\"9\",\"Erin Gammel\",\"Canada\",\"1:02.63\",\"\"\n",
      "\"10\",\"Hannah McLean\",\"New Zealand\",\"1:02.82\",\"\"\n",
      "\"11\",\"Melissa Morgan\",\"Australia\",\"1:02.86\",\"\"\n",
      "\"12\",\"Reiko Nakamura\",\"Japan\",\"1:02.91\",\"\"\n",
      "\"13\",\"Michelle Lischinsky\",\"Canada\",\"1:03.22\",\"\"\n",
      "\"14\",\"Jennifer Fratesi\",\"Canada\",\"1:03.42\",\"\"\n",
      "\"15\",\"Kelly Stefanyshyn\",\"Canada\",\"1:03.44\",\"\"\n",
      "\"16\",\"Clementine Stoney\",\"Australia\",\"1:03.52\",\"\"\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant that answers questions about the table. You only answer the question right after 'Answer: '<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "who was the top ranked swimmer in the semifinals?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Answer: Dyana Calub<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>\n",
      "who was the top ranked swimmer in the semifinals?\n"
     ]
    }
   ],
   "source": [
    "# Test segment ids\n",
    "table_input_segment = result[\"input_ids\"][0][result[\"segment_ids\"][0] == 1]\n",
    "text_input_segment = result[\"input_ids\"][0][result[\"segment_ids\"][0] == 0]\n",
    "print(collator.tokenizer.decode(table_input_segment))\n",
    "print(datasets[\"train\"][0][\"table\"])\n",
    "print(\"-\"*100)\n",
    "print(collator.tokenizer.decode(text_input_segment))\n",
    "print(datasets[\"train\"][0][\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name|\n",
      "Name\n"
     ]
    }
   ],
   "source": [
    "# Test row ids and column ids\n",
    "random_row_index = 1\n",
    "random_column_index = 2\n",
    "input_segment = result[\"input_ids\"][0][(result[\"row_ids\"][0] == random_row_index) & (result[\"column_ids\"][0] == random_column_index)]\n",
    "print(collator.tokenizer.decode(input_segment))\n",
    "# 1 is the row offset and column offset\n",
    "row_offset, column_offset = 1, 1\n",
    "print(collator._convert_csv_string_to_table(datasets[\"train\"][0][\"table\"])[random_row_index - row_offset][random_column_index - column_offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16533,    25, 43048,  3444,  3400,   392])\n",
      "Answer: Dyana Calub\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test labels\n",
    "print(result[\"labels\"][0][result[\"labels\"][0] != -100])\n",
    "print(collator.tokenizer.decode(result[\"labels\"][0][result[\"labels\"][0] != -100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Test attention mask\n",
    "print(result[\"attention_mask\"][0])\n",
    "print(collator.tokenizer.decode(result[\"input_ids\"][0][result[\"attention_mask\"][0] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading the entire dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "ParserError: Error tokenizing data. C error: EOF inside string starting at row 17\n",
      "torch.Size([14140, 17797])\n",
      "torch.Size([14140, 17797])\n",
      "torch.Size([14140, 17797])\n",
      "torch.Size([14140, 17797])\n",
      "torch.Size([14140, 17797])\n"
     ]
    }
   ],
   "source": [
    "# 14149 data points\n",
    "batch_result = collator(datasets[\"train\"])\n",
    "print(batch_result[\"input_ids\"].shape)\n",
    "print(batch_result[\"row_ids\"].shape)\n",
    "print(batch_result[\"column_ids\"].shape)\n",
    "print(batch_result[\"attention_mask\"].shape)\n",
    "print(batch_result[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
