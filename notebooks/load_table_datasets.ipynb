{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant that answers questions about the table. You only answer the question right after 'Answer: '\"\n",
    "ASSISTANT_PROMPT = \"Answer: \"\n",
    "SHUFFLE_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data directory\n",
    "os.makedirs(\"../datasets/self_generated/data\", exist_ok=True)\n",
    "\n",
    "# Create dummy train, validation, and test CSV files\n",
    "dummy_data = pd.DataFrame({\n",
    "    \"context\": [\"table1\", \"table2\"],\n",
    "    \"question\": [\"What is the value in row 1?\", \"What is the value in row 2?\"],\n",
    "    \"answer\": [\"Value 1\", \"Value 2\"]\n",
    "})\n",
    "dummy_data.to_csv(\"../datasets/self_generated/data/train.csv\", index=False)\n",
    "dummy_data.to_csv(\"../datasets/self_generated/data/val.csv\", index=False)\n",
    "dummy_data.to_csv(\"../datasets/self_generated/data/test.csv\", index=False)\n",
    "\n",
    "# Create dummy table files\n",
    "with open(\"../datasets/self_generated/table1.csv\", \"w\") as f:\n",
    "    f.write(\"Column1,Column2\\nValue 1,Value 2\\n\")\n",
    "with open(\"../datasets/self_generated/table2.csv\", \"w\") as f:\n",
    "    f.write(\"Column1,Column2\\nValue 3,Value 4\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", token='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')\n",
    "string = \"What is the capital of France?\"\n",
    "# for i in string:\n",
    "#     token = tokenizer.encode(i, add_special_tokens=False)\n",
    "#     print(i, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableDatasetLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_root: str,\n",
    "        dataset_name: str,\n",
    "        tokenizer: PreTrainedTokenizerFast,\n",
    "        batch_size: int = 4,\n",
    "        table_extension: str = \"html\",\n",
    "        test_max_samples: int = None,\n",
    "        val_max_samples: int = None,\n",
    "        train_max_samples: int = None,\n",
    "        system_prompt: str = SYSTEM_PROMPT,\n",
    "        assistant_prompt: str = ASSISTANT_PROMPT,\n",
    "        user_prompt_order: List[str] = [\"question\", \"table\"],\n",
    "        grid_it: bool = False,\n",
    "        line_length: int = 10,\n",
    "        skip_validation: bool = False\n",
    "    ):\n",
    "        # Initialize instance variables with given parameters\n",
    "        self.dataset_root = dataset_root\n",
    "        self.dataset_name = dataset_name\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.table_extension = table_extension\n",
    "        self.test_max_samples = test_max_samples\n",
    "        self.val_max_samples = val_max_samples\n",
    "        self.train_max_samples = train_max_samples\n",
    "        self.system_prompt = system_prompt\n",
    "        self.assistant_prompt = assistant_prompt\n",
    "        self.user_prompt_order = user_prompt_order\n",
    "        self.grid_it = grid_it\n",
    "        self.line_length = line_length\n",
    "        self.table_pad_token = tokenizer.eos_token\n",
    "        self.start_of_line_token = \"[START_OF_LINE]\"\n",
    "        self.end_of_line_token = \"[END_OF_LINE]\"\n",
    "        self.table_cell_separator_token = \"[TABLE_CELL_SEPARATOR]\"\n",
    "        self.extension_separator_map = {\n",
    "            \"csv\": \",\",\n",
    "            \"html\": \" \",\n",
    "            \"tsv\": \"\\t\"\n",
    "        }\n",
    "        \n",
    "        # Validate the input parameters\n",
    "        if not skip_validation:\n",
    "            self._validate_inputs()\n",
    "        if self.grid_it:\n",
    "            new_tokens = [self.start_of_line_token, self.end_of_line_token, self.table_cell_separator_token]\n",
    "            self.tokenizer.add_tokens(new_tokens)\n",
    "            # TODO: model.resize_token_embeddings(len(tokenizer))\n",
    "        # Set the path to the dataset directory\n",
    "        self.dataset_path = os.path.join(self.dataset_root, self.dataset_name)\n",
    "\n",
    "    def _validate_inputs(self):\n",
    "        # Validate dataset name\n",
    "        if self.dataset_name not in [\"self_generated\", \"wtq\"]:\n",
    "            raise ValueError(f\"Invalid dataset name: {self.dataset_name}\")\n",
    "        # Validate table file extension\n",
    "        if self.table_extension not in [\"csv\", \"html\", \"tsv\"]:\n",
    "            raise ValueError(f\"Invalid table extension: {self.table_extension}\")\n",
    "        # For self_generated datasets, ensure sample sizes are multiples of 80\n",
    "        if self.dataset_name == \"self_generated\":\n",
    "            if self.test_max_samples is not None and self.test_max_samples % 80 != 0:\n",
    "                raise ValueError(\"The number of samples for self-generated dataset must be a multiple of 80\")\n",
    "            if self.val_max_samples is not None and self.val_max_samples % 80 != 0:\n",
    "                raise ValueError(\"The number of samples for self-generated dataset must be a multiple of 80\")\n",
    "            if self.train_max_samples is not None and self.train_max_samples % 80 != 0:\n",
    "                raise ValueError(\"The number of samples for self-generated dataset must be a multiple of 80\")\n",
    "\n",
    "    def _get_table(self, context: str):\n",
    "        # Remove .csv extension from the context if present\n",
    "        context = re.sub(r\"\\.csv$\", \"\", context)\n",
    "        separator = self.extension_separator_map[self.table_extension]\n",
    "        modified_lines = []\n",
    "\n",
    "        with open(os.path.join(self.dataset_path, context + \".\" + self.table_extension), \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                cells = line.strip().split(separator)\n",
    "                modified_line = self.start_of_line_token + self.table_cell_separator_token.join(cells) + self.end_of_line_token\n",
    "                modified_lines.append(modified_line.strip())\n",
    "        # Join the modified lines into a single string\n",
    "        return \"\\n\".join(modified_lines)\n",
    "\n",
    "    def _preprocess_single_example_to_string(self, example):\n",
    "        # Retrieve the table content based on the context provided in the example\n",
    "        table = self._get_table(example[\"context\"])\n",
    "        example[\"table\"] = table\n",
    "\n",
    "        # Construct the user prompt using the specified order of fields\n",
    "        user_prompt = \"\\n\".join([example[col_name] for col_name in self.user_prompt_order if col_name in example])\n",
    "        # Create the system and user messages for the chat template\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "\n",
    "        # Apply the chat template to create the input string\n",
    "        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        text = text + self.assistant_prompt\n",
    "        if self.grid_it:\n",
    "            text = self._grid_it(text)\n",
    "        example[\"input_string\"] = text\n",
    "        return example\n",
    "\n",
    "    def _grid_it(self, text):\n",
    "        # Seperate the text into before_table, table, and after_table\n",
    "        table_pattern = r\"(\\[START_OF_LINE\\].*?\\[END_OF_LINE\\](?:\\n\\[START_OF_LINE\\].*?\\[END_OF_LINE\\])*)\"\n",
    "        parts = re.split(table_pattern, text, maxsplit=1)\n",
    "        before_table = parts[0].strip()\n",
    "        table = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "        after_table = parts[2].strip() if len(parts) > 2 else \"\"\n",
    "\n",
    "        # Special token ids\n",
    "        start_of_line_token = self.tokenizer.encode(self.start_of_line_token, add_special_tokens=False)[0]\n",
    "        end_of_line_token = self.tokenizer.encode(self.end_of_line_token, add_special_tokens=False)[0]\n",
    "        table_cell_separator_token = self.tokenizer.encode(self.table_cell_separator_token, add_special_tokens=False)[0]\n",
    "        pad_token_id = self.tokenizer.encode(self.table_pad_token, add_special_tokens=False)[0]\n",
    "\n",
    "        # before_table\n",
    "        before_table_tokens = self.tokenizer.encode(before_table, add_special_tokens=False)\n",
    "        before_table_pad_count = self.line_length - len(before_table_tokens) % self.line_length\n",
    "        before_table_tokens.extend([pad_token_id] * before_table_pad_count)\n",
    "\n",
    "        # table\n",
    "        table_tokens = self.tokenizer.encode(table, add_special_tokens=False)\n",
    "        rows = table.strip().split(\"\\n\")\n",
    "        col_count = len(rows[0].split(self.table_cell_separator_token))\n",
    "        row_count = len(rows)\n",
    "        table_grid = np.full((row_count, self.line_length), pad_token_id, dtype=object)\n",
    "\n",
    "        # Get the max token number per column\n",
    "        token_num_per_cell = []\n",
    "        token_row = []\n",
    "        token_counter_in_row = 0\n",
    "        token_counter_in_cell = 0\n",
    "        for id in table_tokens:\n",
    "            token_counter_in_row += 1\n",
    "            \n",
    "            if id == start_of_line_token:\n",
    "                token_row = []\n",
    "                token_counter_in_cell = 0\n",
    "                token_counter_in_row = 1\n",
    "            elif id == end_of_line_token:\n",
    "                token_row.append(token_counter_in_cell)\n",
    "                token_num_per_cell.append(token_row)\n",
    "                token_row = []\n",
    "                token_counter_in_cell = 0\n",
    "            elif id == table_cell_separator_token:\n",
    "                token_row.append(token_counter_in_cell)\n",
    "                token_counter_in_cell = 0\n",
    "            else:\n",
    "                token_counter_in_cell += 1\n",
    "        token_num_per_cell = np.array(token_num_per_cell)\n",
    "        max_token_num_per_cell = np.max(token_num_per_cell, axis = 0)\n",
    "        pad_token_count = self.line_length - sum(max_token_num_per_cell)\n",
    "        if pad_token_count < 0:\n",
    "            print(\"The token number in the row exceeds the line length\")\n",
    "            # TODO: discard this data\n",
    "        \n",
    "\n",
    "        # Fill the table grid\n",
    "        token_col_cursor = self.line_length - 1\n",
    "        token_row_cursor = row_count - 1\n",
    "        cell_col_cursor = col_count - 1\n",
    "        cell_inner_token_counter = 0\n",
    "\n",
    "        for id in reversed(table_tokens):\n",
    "            current_cell_token_num = max_token_num_per_cell[cell_col_cursor]\n",
    "            if id == start_of_line_token:\n",
    "                token_row_cursor -= 1\n",
    "            elif id == end_of_line_token:\n",
    "                cell_col_cursor = col_count - 1\n",
    "                token_col_cursor = self.line_length - 1\n",
    "                table_grid[token_row_cursor, token_col_cursor - pad_token_count + 1:] = pad_token_id\n",
    "                token_col_cursor -= pad_token_count\n",
    "                cell_inner_token_counter = 0\n",
    "            elif id == table_cell_separator_token:\n",
    "                need_to_pad_token_count = current_cell_token_num - cell_inner_token_counter\n",
    "                table_grid[token_row_cursor, token_col_cursor - need_to_pad_token_count + 1 : token_col_cursor + 1] = pad_token_id\n",
    "                token_col_cursor -= need_to_pad_token_count\n",
    "                cell_inner_token_counter = 0\n",
    "            else:\n",
    "                table_grid[token_row_cursor, token_col_cursor] = id\n",
    "                token_col_cursor -= 1\n",
    "                cell_inner_token_counter += 1\n",
    "        \n",
    "        # after_table\n",
    "        after_table_tokens = self.tokenizer.encode(after_table, add_special_tokens=False)\n",
    "        after_table_pad_count = self.line_length - len(after_table_tokens) % self.line_length\n",
    "        after_table_tokens.extend([pad_token_id] * after_table_pad_count)\n",
    "\n",
    "        # Concatenate the three grids and flatten the result\n",
    "        result = np.concatenate((before_table_tokens, table_grid.flatten(), after_table_tokens), axis=0)\n",
    "        for i in result:\n",
    "            print(i, self.tokenizer.decode(i))\n",
    "        # print(result)\n",
    "        return self.tokenizer.decode(result)\n",
    "\n",
    "    def _tokenize_function(self, examples):\n",
    "        # Tokenize the input strings with padding and truncation\n",
    "        return self.tokenizer(examples[\"input_string\"], padding=True, truncation=True)\n",
    "\n",
    "    def load(self):\n",
    "        # Load the dataset from CSV files\n",
    "        dataset = datasets.load_dataset(\"csv\", data_files={\n",
    "            \"train\": os.path.join(self.dataset_path, \"data\", \"train.csv\"),\n",
    "            \"test\": os.path.join(self.dataset_path, \"data\", \"test.csv\"),\n",
    "            \"validation\": os.path.join(self.dataset_path, \"data\", \"val.csv\")\n",
    "        })\n",
    "\n",
    "        # Shuffle the dataset based on the dataset name\n",
    "        if self.dataset_name == \"wtq\":\n",
    "            dataset = dataset.shuffle(seed=SHUFFLE_SEED)\n",
    "        elif self.dataset_name == \"self_generated\":\n",
    "            dataset[\"train\"] = dataset[\"train\"].shuffle(seed=SHUFFLE_SEED)\n",
    "\n",
    "        # Select a subset of samples if max sample limits are specified\n",
    "        if self.test_max_samples is not None:\n",
    "            dataset[\"test\"] = dataset[\"test\"].select(range(self.test_max_samples))\n",
    "        if self.val_max_samples is not None:\n",
    "            dataset[\"validation\"] = dataset[\"validation\"].select(range(self.val_max_samples))\n",
    "        if self.train_max_samples is not None:\n",
    "            dataset[\"train\"] = dataset[\"train\"].select(range(self.train_max_samples))\n",
    "        \n",
    "        # print(dataset)\n",
    "        # Preprocess each example to generate input strings\n",
    "        dataset = dataset.map(self._preprocess_single_example_to_string, batched=False)\n",
    "\n",
    "        # Set tokenizer padding and padding side\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.tokenizer.padding_side = \"left\"\n",
    "\n",
    "        # Tokenize the dataset\n",
    "        dataset = dataset.map(self._tokenize_function, batched=True, batch_size=self.batch_size)\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79d8be75cf74935a56a8cba4223fef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "9125 system\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "38766 Cut\n",
      "1303 ting\n",
      "33025  Knowledge\n",
      "2696  Date\n",
      "25 :\n",
      "6790  December\n",
      "220  \n",
      "2366 202\n",
      "18 3\n",
      "198 \n",
      "\n",
      "15724 Today\n",
      "2696  Date\n",
      "25 :\n",
      "220  \n",
      "1627 26\n",
      "10263  Jul\n",
      "220  \n",
      "2366 202\n",
      "19 4\n",
      "271 \n",
      "\n",
      "\n",
      "2675 You\n",
      "527  are\n",
      "264  a\n",
      "11190  helpful\n",
      "18328  assistant\n",
      "430  that\n",
      "11503  answers\n",
      "4860  questions\n",
      "922  about\n",
      "279  the\n",
      "2007  table\n",
      "13 .\n",
      "1472  You\n",
      "1193  only\n",
      "4320  answer\n",
      "279  the\n",
      "3488  question\n",
      "1314  right\n",
      "1306  after\n",
      "364  '\n",
      "16533 Answer\n",
      "25 :\n",
      "364  '\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "3923 What\n",
      "374  is\n",
      "279  the\n",
      "907  value\n",
      "304  in\n",
      "2872  row\n",
      "220  \n",
      "17 2\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "16 1\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "1150 Value\n",
      "220  \n",
      "18 3\n",
      "1150 Value\n",
      "220  \n",
      "19 4\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "16533 Answer\n",
      "25 :\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "9125 system\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "38766 Cut\n",
      "1303 ting\n",
      "33025  Knowledge\n",
      "2696  Date\n",
      "25 :\n",
      "6790  December\n",
      "220  \n",
      "2366 202\n",
      "18 3\n",
      "198 \n",
      "\n",
      "15724 Today\n",
      "2696  Date\n",
      "25 :\n",
      "220  \n",
      "1627 26\n",
      "10263  Jul\n",
      "220  \n",
      "2366 202\n",
      "19 4\n",
      "271 \n",
      "\n",
      "\n",
      "2675 You\n",
      "527  are\n",
      "264  a\n",
      "11190  helpful\n",
      "18328  assistant\n",
      "430  that\n",
      "11503  answers\n",
      "4860  questions\n",
      "922  about\n",
      "279  the\n",
      "2007  table\n",
      "13 .\n",
      "1472  You\n",
      "1193  only\n",
      "4320  answer\n",
      "279  the\n",
      "3488  question\n",
      "1314  right\n",
      "1306  after\n",
      "364  '\n",
      "16533 Answer\n",
      "25 :\n",
      "364  '\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "3923 What\n",
      "374  is\n",
      "279  the\n",
      "907  value\n",
      "304  in\n",
      "2872  row\n",
      "220  \n",
      "16 1\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "16 1\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "1150 Value\n",
      "220  \n",
      "16 1\n",
      "1150 Value\n",
      "220  \n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "16533 Answer\n",
      "25 :\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b2d83b78284118bf2230dad210961b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "9125 system\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "38766 Cut\n",
      "1303 ting\n",
      "33025  Knowledge\n",
      "2696  Date\n",
      "25 :\n",
      "6790  December\n",
      "220  \n",
      "2366 202\n",
      "18 3\n",
      "198 \n",
      "\n",
      "15724 Today\n",
      "2696  Date\n",
      "25 :\n",
      "220  \n",
      "1627 26\n",
      "10263  Jul\n",
      "220  \n",
      "2366 202\n",
      "19 4\n",
      "271 \n",
      "\n",
      "\n",
      "2675 You\n",
      "527  are\n",
      "264  a\n",
      "11190  helpful\n",
      "18328  assistant\n",
      "430  that\n",
      "11503  answers\n",
      "4860  questions\n",
      "922  about\n",
      "279  the\n",
      "2007  table\n",
      "13 .\n",
      "1472  You\n",
      "1193  only\n",
      "4320  answer\n",
      "279  the\n",
      "3488  question\n",
      "1314  right\n",
      "1306  after\n",
      "364  '\n",
      "16533 Answer\n",
      "25 :\n",
      "364  '\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "3923 What\n",
      "374  is\n",
      "279  the\n",
      "907  value\n",
      "304  in\n",
      "2872  row\n",
      "220  \n",
      "16 1\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "16 1\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "1150 Value\n",
      "220  \n",
      "16 1\n",
      "1150 Value\n",
      "220  \n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "16533 Answer\n",
      "25 :\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "9125 system\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "38766 Cut\n",
      "1303 ting\n",
      "33025  Knowledge\n",
      "2696  Date\n",
      "25 :\n",
      "6790  December\n",
      "220  \n",
      "2366 202\n",
      "18 3\n",
      "198 \n",
      "\n",
      "15724 Today\n",
      "2696  Date\n",
      "25 :\n",
      "220  \n",
      "1627 26\n",
      "10263  Jul\n",
      "220  \n",
      "2366 202\n",
      "19 4\n",
      "271 \n",
      "\n",
      "\n",
      "2675 You\n",
      "527  are\n",
      "264  a\n",
      "11190  helpful\n",
      "18328  assistant\n",
      "430  that\n",
      "11503  answers\n",
      "4860  questions\n",
      "922  about\n",
      "279  the\n",
      "2007  table\n",
      "13 .\n",
      "1472  You\n",
      "1193  only\n",
      "4320  answer\n",
      "279  the\n",
      "3488  question\n",
      "1314  right\n",
      "1306  after\n",
      "364  '\n",
      "16533 Answer\n",
      "25 :\n",
      "364  '\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "3923 What\n",
      "374  is\n",
      "279  the\n",
      "907  value\n",
      "304  in\n",
      "2872  row\n",
      "220  \n",
      "17 2\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "16 1\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "1150 Value\n",
      "220  \n",
      "18 3\n",
      "1150 Value\n",
      "220  \n",
      "19 4\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "16533 Answer\n",
      "25 :\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132cac1862434af3a061a7018586112c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "9125 system\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "38766 Cut\n",
      "1303 ting\n",
      "33025  Knowledge\n",
      "2696  Date\n",
      "25 :\n",
      "6790  December\n",
      "220  \n",
      "2366 202\n",
      "18 3\n",
      "198 \n",
      "\n",
      "15724 Today\n",
      "2696  Date\n",
      "25 :\n",
      "220  \n",
      "1627 26\n",
      "10263  Jul\n",
      "220  \n",
      "2366 202\n",
      "19 4\n",
      "271 \n",
      "\n",
      "\n",
      "2675 You\n",
      "527  are\n",
      "264  a\n",
      "11190  helpful\n",
      "18328  assistant\n",
      "430  that\n",
      "11503  answers\n",
      "4860  questions\n",
      "922  about\n",
      "279  the\n",
      "2007  table\n",
      "13 .\n",
      "1472  You\n",
      "1193  only\n",
      "4320  answer\n",
      "279  the\n",
      "3488  question\n",
      "1314  right\n",
      "1306  after\n",
      "364  '\n",
      "16533 Answer\n",
      "25 :\n",
      "364  '\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "3923 What\n",
      "374  is\n",
      "279  the\n",
      "907  value\n",
      "304  in\n",
      "2872  row\n",
      "220  \n",
      "16 1\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "16 1\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "1150 Value\n",
      "220  \n",
      "16 1\n",
      "1150 Value\n",
      "220  \n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "16533 Answer\n",
      "25 :\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "9125 system\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "38766 Cut\n",
      "1303 ting\n",
      "33025  Knowledge\n",
      "2696  Date\n",
      "25 :\n",
      "6790  December\n",
      "220  \n",
      "2366 202\n",
      "18 3\n",
      "198 \n",
      "\n",
      "15724 Today\n",
      "2696  Date\n",
      "25 :\n",
      "220  \n",
      "1627 26\n",
      "10263  Jul\n",
      "220  \n",
      "2366 202\n",
      "19 4\n",
      "271 \n",
      "\n",
      "\n",
      "2675 You\n",
      "527  are\n",
      "264  a\n",
      "11190  helpful\n",
      "18328  assistant\n",
      "430  that\n",
      "11503  answers\n",
      "4860  questions\n",
      "922  about\n",
      "279  the\n",
      "2007  table\n",
      "13 .\n",
      "1472  You\n",
      "1193  only\n",
      "4320  answer\n",
      "279  the\n",
      "3488  question\n",
      "1314  right\n",
      "1306  after\n",
      "364  '\n",
      "16533 Answer\n",
      "25 :\n",
      "364  '\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "3923 What\n",
      "374  is\n",
      "279  the\n",
      "907  value\n",
      "304  in\n",
      "2872  row\n",
      "220  \n",
      "17 2\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "16 1\n",
      "128009 <|eot_id|>\n",
      "3006 Column\n",
      "17 2\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "1150 Value\n",
      "220  \n",
      "18 3\n",
      "1150 Value\n",
      "220  \n",
      "19 4\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "16533 Answer\n",
      "25 :\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n",
      "128009 <|eot_id|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fcba822313417fbd909d74b4a92c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32253dc01d8d4f3382be484e7d9fb42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43911adb3ba4cb8bbd39d1dae378ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define dataset root and name\n",
    "dataset_root = \"../datasets\"\n",
    "dataset_name = \"self_generated\"\n",
    "\n",
    "# Create an instance of TableDatasetLoader\n",
    "loader = TableDatasetLoader(\n",
    "    dataset_root=dataset_root,\n",
    "    dataset_name=dataset_name,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=2,\n",
    "    table_extension=\"csv\",\n",
    "    test_max_samples=2,\n",
    "    val_max_samples=2,\n",
    "    train_max_samples=2,\n",
    "    grid_it=True,\n",
    "    skip_validation = True\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = loader.load()\n",
    "\n",
    "# Print a few examples from the training set\n",
    "# print(dataset[\"train\"][0][\"input_string\"])\n",
    "# print(dataset[\"train\"][0][\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
