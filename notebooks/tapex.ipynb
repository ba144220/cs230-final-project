{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad51f09-1777-418f-8b50-18a0873d4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM,\n",
    "    HfArgumentParser,\n",
    "    TapexTokenizer, BartForConditionalGeneration\n",
    ")\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"../src\"))\n",
    "datasets_path = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"../datasets\"))\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "if datasets_path not in sys.path:\n",
    "    sys.path.append(datasets_path)\n",
    "\n",
    "from parsers.argument_classes import DatasetArguments\n",
    "from utils.datasets_loader import load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb912494-001c-4fbb-9417-bc6759a1a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_csv_string_to_table(csv_string: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a csv string to a table, including the header\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(StringIO(csv_string), delimiter=\",\", on_bad_lines=\"skip\")\n",
    "    columns = df.columns.astype(str).tolist()\n",
    "    columns = [col.replace(\"Unnamed: 0\", \"\") for col in columns]\n",
    "    rows = df.values.astype(str).tolist()\n",
    "    return pd.DataFrame(rows, columns = columns)\n",
    "\n",
    "def main():\n",
    "    parser = HfArgumentParser(DatasetArguments)\n",
    "    dataset_args = parser.parse_dict({\n",
    "    \"dataset_root_dir\" : \"../datasets\",\n",
    "    \"train_max_samples_for_each_dataset\" : 10,\n",
    "    \"dataset_names\": [\"wtq\"],\n",
    "    })[0]\n",
    "    \n",
    "    # Load datasets\n",
    "    def filter_function(example):\n",
    "        if dataset_args.max_table_row_num is not None and example[\"table_row_num\"] > dataset_args.max_table_row_num:\n",
    "            return False\n",
    "        if dataset_args.max_table_width is not None and example[\"table_width\"] > dataset_args.max_table_width:\n",
    "            return False\n",
    "        return True\n",
    "    datasets = load_datasets(dataset_args, filter_function=filter_function)\n",
    "    # Tokenizer\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n",
    "    \n",
    "    # # Model\n",
    "    # model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n",
    "    tokenizer = TapexTokenizer.from_pretrained(\"microsoft/tapex-base\")\n",
    "    model = BartForConditionalGeneration.from_pretrained(\"microsoft/tapex-base\")\n",
    "    question = datasets[\"test\"]['question'][0]\n",
    "    table = datasets[\"test\"][\"table\"][0]\n",
    "\n",
    "    df = _convert_csv_string_to_table(table)\n",
    "    encoding = tokenizer(df, question, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model.generate(**encoding)\n",
    "    predicted_answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Answer:\", predicted_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6faf055-7793-4d94-9859-3e1a44ee7508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce2dc46f15143ff9384630d91916c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ce8f22ef484d0ab7af5b072a911cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e7465290ff48ee920c50ae094f0870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e5e76280624181aa8090b13e3cb00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb14153d14d4d0692f39bc465961169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3515 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b811f4cd3f4357a345a538ec405aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d4b471e6fb4c03963c138f839ec942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deaa68a2b32f459294bd7feb083c68cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3515 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b746eae29bf4fd9b2ea8b1ef7df5cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0760dbb56c3c4dbebbcf4bc3b6b7d500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3efe3937f0474abf843149a32c1c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73bbdda94604721ae1c4919775c6584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yejuahn/opt/anaconda3/envs/cs230/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7ebfbe3be747369ecb68412ace3fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/988 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d3024d71024076827614a447ee390d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6fdd24dc5484f01be25b86d87c0db1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yejuahn/opt/anaconda3/envs/cs230/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: did dmitry mikhailovich golitsyn or andrey kirillovich razumovsky serve as ambassador longer?\n",
      "Answer: [', dmitry mikhailovich golitsyn, andrey kirillovich']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230",
   "language": "python",
   "name": "cs230"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
