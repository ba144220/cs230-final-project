# Model arguments
model_name: meta-llama/Llama-3.2-1B-Instruct
adapter_path: ./outputs/run_20241110_182848
load_in_4bit: true
load_in_8bit: false

line_length: 32
channel_period: 32
x_channel_offset: 30
y_channel_offset: 31

# Dataset arguments
dataset_root_dir: ./datasets
dataset_names: ["self_generated", "wtq"]
table_extension: csv
train_max_samples_for_each_dataset: 80
val_max_samples_for_each_dataset: 80
test_max_samples_for_each_dataset: 80
shuffle_seed: 42

# max_table_row_num: 32
# max_table_width: 64

# Training arguments
batch_size: 4
max_seq_length: 1024
