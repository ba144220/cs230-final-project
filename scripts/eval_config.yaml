# Model arguments
model_name: meta-llama/Llama-3.2-1B-Instruct
adapter_path: ./outputs/run_20241110_182848
load_in_4bit: false
load_in_8bit: true
line_length: 32
channel_period: 4
x_channel_offset: 2
y_channel_offset: 3

# Dataset arguments
dataset_root_dir: ./datasets
dataset_names: ["self_generated", "wtq"]
table_extension: csv
train_max_samples_for_each_dataset: 80
val_max_samples_for_each_dataset: 480
test_max_samples_for_each_dataset: 480
shuffle_seed: 42

# Training arguments
batch_size: 8
max_seq_length: 1024
